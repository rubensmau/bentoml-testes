{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BentoML Example: Fast AI with Tabular data\n",
    "\n",
    "**BentoML makes moving trained ML models to production easy:**\n",
    "\n",
    "* Package models trained with **any ML framework** and reproduce them for model serving in production\n",
    "* **Deploy anywhere** for online API serving or offline batch serving\n",
    "* High-Performance API model server with *adaptive micro-batching* support\n",
    "* Central hub for managing models and deployment process via Web UI and APIs\n",
    "* Modular and flexible design making it *adaptable to your infrastrcuture*\n",
    "\n",
    "BentoML is a framework for serving, managing, and deploying machine learning models. It is aiming to bridge the gap between Data Science and DevOps, and enable teams to deliver prediction services in a fast, repeatable, and scalable way.\n",
    "Before reading this example project, be sure to check out the [Getting started guide](https://github.com/bentoml/BentoML/blob/master/guides/quick-start/bentoml-quick-start-guide.ipynb) to learn about the basic concepts in BentoML.\n",
    "\n",
    "\n",
    "This notebook is based on fastai v1's cours v3 lesson 4.  It will train a model that predict salary range base on the data we provided.\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=fast-ai&ea=fast-ai-salary-range-prediction&dt=fast-ai-salary-range-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q -U 'fastai<=1.0.61'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'salary'\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TabularList.from_df(df.iloc[800:1000].copy(), path=path, cat_names=cat_names, cont_names=cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
    "                           .split_by_idx(list(range(800,1000)))\n",
    "                           .label_from_df(cols=dep_var)\n",
    "                           .add_test(test)\n",
    "                           .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>2.5957</td>\n",
       "      <td>-0.0779</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>11th</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>2.4491</td>\n",
       "      <td>-1.4279</td>\n",
       "      <td>-1.2046</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>1.6428</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>-0.2710</td>\n",
       "      <td>-0.0312</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.3476</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>-0.6640</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.9959</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>-0.4224</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.2891</td>\n",
       "      <td>0.3968</td>\n",
       "      <td>-0.0312</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.3624</td>\n",
       "      <td>-1.4083</td>\n",
       "      <td>-0.0312</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.6294</td>\n",
       "      <td>-0.6502</td>\n",
       "      <td>1.1422</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch(rows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(data, layers=[200,100], metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.351867</td>\n",
       "      <td>0.388441</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category tensor(1), tensor(1), tensor([0.4563, 0.5437]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df.iloc[0] # sample input date for testing\n",
    "\n",
    "learn.predict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                49\n",
       "workclass                     Private\n",
       "fnlwgt                         101320\n",
       "education                  Assoc-acdm\n",
       "education-num                    12.0\n",
       "marital-status     Married-civ-spouse\n",
       "occupation                        NaN\n",
       "relationship                     Wife\n",
       "race                            White\n",
       "sex                            Female\n",
       "capital-gain                        0\n",
       "capital-loss                     1902\n",
       "hours-per-week                     40\n",
       "native-country          United-States\n",
       "salary                          >=50k\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BentoService for model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tabular_csv.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tabular_csv.py\n",
    "\n",
    "from bentoml import env, api, artifacts, BentoService\n",
    "from bentoml.frameworks.fastai import Fastai1ModelArtifact\n",
    "from bentoml.adapters import DataframeInput\n",
    "\n",
    "\n",
    "@env(pip_packages=['fastai'])\n",
    "@artifacts([Fastai1ModelArtifact('model')])\n",
    "class FastaiTabularModel(BentoService):\n",
    "    \n",
    "    @api(input=DataframeInput(), batch=True)\n",
    "    def predict(self, df):\n",
    "        results = []\n",
    "        for _, row in df.iterrows():       \n",
    "            prediction = self.artifacts.model.predict(row)\n",
    "            results.append(prediction[0].obj)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save BentoService to file archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-11 15:32:56,972] INFO - Detected zipimporter <zipimporter object \"/home/ec2-user/anaconda3/lib/python3.7/site-packages/locket-0.2.1-py3.7.egg\">\n",
      "[2021-03-11 15:32:56,976] WARNING - BentoML by default does not include spacy and torchvision package when using FastaiModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2021-03-11 15:32:56,978] WARNING - Overwriting existing pip package requirement 'fastai==1.0.61' to 'fastai<2.0.0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-11 15:32:57,857] INFO - BentoService bundle 'FastaiTabularModel:20210311153257_2D1346' saved to: /home/ec2-user/bentoml/repository/FastaiTabularModel/20210311153257_2D1346\n"
     ]
    }
   ],
   "source": [
    "# 1) import the custom BentoService defined above\n",
    "from tabular_csv import FastaiTabularModel\n",
    "\n",
    "# 2) `pack` it with required artifacts\n",
    "svc = FastaiTabularModel()\n",
    "svc.pack('model', learn)\n",
    "\n",
    "# 3) save your BentoSerivce\n",
    "saved_path = svc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST API Model Serving\n",
    "\n",
    "\n",
    "To start a REST API model server with the BentoService saved above, use the bentoml serve command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "[2021-03-11 15:33:07,972] INFO - Getting latest version FastaiTabularModel:20210311153257_2D1346\n",
      "[2021-03-11 15:33:07,972] INFO - Starting BentoML API server in development mode..\n",
      "[2021-03-11 15:33:08,240] INFO - Detected zipimporter <zipimporter object \"/home/ec2-user/bentoml/repository/FastaiTabularModel/20210311153257_2D1346/FastaiTabularModel/zipimports/locket-0.2.1-py3.7.egg\">\n",
      "[2021-03-11 15:33:09,737] WARNING - BentoML by default does not include spacy and torchvision package when using FastaiModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2021-03-11 15:33:09,739] WARNING - Overwriting existing pip package requirement 'fastai==1.0.61' to 'fastai<2.0.0'\n",
      " * Serving Flask app \"FastaiTabularModel\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "[2021-03-11 15:34:07,368] INFO - {'service_name': 'FastaiTabularModel', 'service_version': '20210311153257_2D1346', 'api': 'predict', 'task': {'data': '[{\\n  \"age\": 49,\\n  \"workclass\": \"Private\",\\n  \"fnlwgt\": 101320,\\n  \"education\": \"Assoc-acdm\",\\n  \"education-num\": 12.0,\\n  \"marital-status\": \"Married-civ-spouse\",\\n  \"occupation\": \"\",\\n  \"relationship\": \"Wift\",\\n  \"race\": \"White\",\\n  \"sex\": \"Female\",\\n  \"capital-gain\": 0,\\n  \"capital-loss\": 1902,\\n  \"hours-per-week\": 40,\\n  \"native-country\": \"United-States\",\\n  \"salary\": \">=50k\"\\n}]', 'task_id': 'b66b6c4f-e5a5-44dd-a079-82ebb0aacc40', 'batch': 1, 'http_headers': (('Host', '127.0.0.1:5000'), ('User-Agent', 'curl/7.69.1'), ('Accept', '*/*'), ('Content-Type', 'application/json'), ('Content-Length', '370'))}, 'result': {'data': '[\"<50k\"]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': 'b66b6c4f-e5a5-44dd-a079-82ebb0aacc40'}\n",
      "127.0.0.1 - - [11/Mar/2021 15:34:07] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
      "[2021-03-11 15:43:29,799] INFO - {'service_name': 'FastaiTabularModel', 'service_version': '20210311153257_2D1346', 'api': 'predict', 'task': {'data': '[{\\n  \"age\": 49,\\n  \"workclass\": \"Private\",\\n  \"fnlwgt\": 101320,\\n  \"education\": \"Assoc-acdm\",\\n  \"education-num\": 12.0,\\n  \"marital-status\": \"Married-civ-spouse\",\\n  \"occupation\": \"\",\\n  \"relationship\": \"Wift\",\\n  \"race\": \"White\",\\n  \"sex\": \"Female\",\\n  \"capital-gain\": 0,\\n  \"capital-loss\": 1902,\\n  \"hours-per-week\": 40,\\n  \"native-country\": \"United-States\",\\n  \"salary\": \">=50k\"\\n}]', 'task_id': '89b4caf0-1fa3-4085-b5c1-a05074a74507', 'batch': 1, 'http_headers': (('Host', '127.0.0.1:5000'), ('User-Agent', 'curl/7.69.1'), ('Accept', '*/*'), ('Content-Type', 'application/json'), ('Content-Length', '370'))}, 'result': {'data': '[\"<50k\"]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '89b4caf0-1fa3-4085-b5c1-a05074a74507'}\n",
      "127.0.0.1 - - [11/Mar/2021 15:43:29] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve FastaiTabularModel:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running this notebook from Google Colab, you can start the dev server with `--run-with-ngrok` option, to gain acccess to the API endpoint via a public endpoint managed by [ngrok](https://ngrok.com/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve FastaiTabularModel:latest --run-with-ngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send prediction requeset to the REST API server\n",
    "\n",
    "#### JSON Request\n",
    "\n",
    "```bash\n",
    "curl -X POST \\\n",
    "  http://localhost:5000/predict \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '[{\n",
    "  \"age\": 49,\n",
    "  \"workclass\": \"Private\",\n",
    "  \"fnlwgt\": 101320,\n",
    "  \"education\": \"Assoc-acdm\",\n",
    "  \"education-num\": 12.0,\n",
    "  \"marital-status\": \"Married-civ-spouse\",\n",
    "  \"occupation\": \"\",\n",
    "  \"relationship\": \"Wift\",\n",
    "  \"race\": \"White\",\n",
    "  \"sex\": \"Female\",\n",
    "  \"capital-gain\": 0,\n",
    "  \"capital-loss\": 1902,\n",
    "  \"hours-per-week\": 40,\n",
    "  \"native-country\": \"United-States\",\n",
    "  \"salary\": \">=50k\"\n",
    "}]'\n",
    "```\n",
    "\n",
    "#### CSV Request\n",
    "\n",
    "```bash\n",
    "curl -X POST \"http://127.0.0.1:5000/predict\" \\\n",
    "    -H \"Content-Type: text/csv\" \\\n",
    "    --data-binary @test.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containerize model server with Docker\n",
    "\n",
    "\n",
    "One common way of distributing this model API server for production deployment, is via Docker containers. And BentoML provides a convenient way to do that.\n",
    "\n",
    "Note that docker is **not available in Google Colab**. You will need to download and run this notebook locally to try out this containerization with docker feature.\n",
    "\n",
    "If you already have docker configured, simply run the follow command to product a docker container serving the IrisClassifier prediction service created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "[2021-03-11 16:46:28,489] INFO - Getting latest version FastaiTabularModel:20210311153257_2D1346\n",
      "\u001b[39mFound Bento: /home/ec2-user/bentoml/repository/FastaiTabularModel/20210311153257_2D1346\u001b[0m\n",
      "Containerizing FastaiTabularModel:20210311153257_2D1346 with local YataiService and docker daemon from local environment|\u001b[32mBuild container image: fastaitabularmodel:20210311153257_2D1346\u001b[0m\n",
      "\b \r"
     ]
    }
   ],
   "source": [
    "!bentoml containerize FastaiTabularModel:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tabular_csv.FastaiTabularModel"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastaiTabularModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client:\r\n",
      " Debug Mode: false\r\n",
      "\r\n",
      "Server:\r\n",
      " Containers: 31\r\n",
      "  Running: 0\r\n",
      "  Paused: 0\r\n",
      "  Stopped: 31\r\n",
      " Images: 37\r\n",
      " Server Version: 19.03.13-ce\r\n",
      " Storage Driver: overlay2\r\n",
      "  Backing Filesystem: xfs\r\n",
      "  Supports d_type: true\r\n",
      "  Native Overlay Diff: true\r\n",
      " Logging Driver: json-file\r\n",
      " Cgroup Driver: cgroupfs\r\n",
      " Plugins:\r\n",
      "  Volume: local\r\n",
      "  Network: bridge host ipvlan macvlan null overlay\r\n",
      "  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\r\n",
      " Swarm: inactive\r\n",
      " Runtimes: neuron nvidia runc\r\n",
      " Default Runtime: runc\r\n",
      " Init Binary: docker-init\r\n",
      " containerd version: c623d1b36f09f8ef6536a057bd658b3aa8632828\r\n",
      " runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff\r\n",
      " init version: de40ad0 (expected: fec3683)\r\n",
      " Security Options:\r\n",
      "  seccomp\r\n",
      "   Profile: default\r\n",
      " Kernel Version: 4.14.219-161.340.amzn2.x86_64\r\n",
      " Operating System: Amazon Linux 2\r\n",
      " OSType: linux\r\n",
      " Architecture: x86_64\r\n",
      " CPUs: 4\r\n",
      " Total Memory: 7.296GiB\r\n",
      " Name: ip-172-31-1-118.us-east-2.compute.internal\r\n",
      " ID: ULQY:BXOT:K6WH:QM6E:IDFQ:2EML:NOQB:UQ4O:X2YL:YWSB:FIVU:LCEV\r\n",
      " Docker Root Dir: /var/lib/docker\r\n",
      " Debug Mode: false\r\n",
      " Registry: https://index.docker.io/v1/\r\n",
      " Labels:\r\n",
      " Experimental: false\r\n",
      " Insecure Registries:\r\n",
      "  127.0.0.0/8\r\n",
      " Live Restore Enabled: false\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-11 16:59:44,222] INFO - Starting BentoML API server in production mode..\n",
      "[2021-03-11 16:59:44,374] INFO - get_gunicorn_num_of_workers: 3, calculated by cpu count\n",
      "[2021-03-11 16:59:44 +0000] [1] [INFO] Starting gunicorn 20.0.4\n",
      "[2021-03-11 16:59:44 +0000] [1] [INFO] Listening at: http://0.0.0.0:5000 (1)\n",
      "[2021-03-11 16:59:44 +0000] [1] [INFO] Using worker: sync\n",
      "[2021-03-11 16:59:44 +0000] [11] [INFO] Booting worker with pid: 11\n",
      "[2021-03-11 16:59:44 +0000] [12] [INFO] Booting worker with pid: 12\n",
      "[2021-03-11 16:59:44 +0000] [13] [INFO] Booting worker with pid: 13\n",
      "[2021-03-11 16:59:44,628] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.7.10, but current environment version is 3.7.6.\n",
      "[2021-03-11 16:59:44,640] INFO - Detected zipimporter <zipimporter object \"/bento/FastaiTabularModel/zipimports/locket-0.2.1-py3.7.egg\">\n",
      "[2021-03-11 16:59:44,705] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.7.10, but current environment version is 3.7.6.\n",
      "[2021-03-11 16:59:44,718] INFO - Detected zipimporter <zipimporter object \"/bento/FastaiTabularModel/zipimports/locket-0.2.1-py3.7.egg\">\n",
      "[2021-03-11 16:59:44,783] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.7.10, but current environment version is 3.7.6.\n",
      "[2021-03-11 16:59:44,802] INFO - Detected zipimporter <zipimporter object \"/bento/FastaiTabularModel/zipimports/locket-0.2.1-py3.7.egg\">\n",
      "[2021-03-11 16:59:46,159] WARNING - BentoML by default does not include spacy and torchvision package when using FastaiModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2021-03-11 16:59:46,161] WARNING - Overwriting existing pip package requirement 'fastai==1.0.61' to 'fastai<2.0.0'\n",
      "[2021-03-11 16:59:46,390] WARNING - BentoML by default does not include spacy and torchvision package when using FastaiModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2021-03-11 16:59:46,392] WARNING - Overwriting existing pip package requirement 'fastai==1.0.61' to 'fastai<2.0.0'\n",
      "[2021-03-11 16:59:46,447] WARNING - BentoML by default does not include spacy and torchvision package when using FastaiModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2021-03-11 16:59:46,448] WARNING - Overwriting existing pip package requirement 'fastai==1.0.61' to 'fastai<2.0.0'\n",
      "[2021-03-11 17:00:05,162] INFO - {'service_name': 'FastaiTabularModel', 'service_version': '20210311153257_2D1346', 'api': 'predict', 'task': {'data': '[{\\n  \"age\": 49,\\n  \"workclass\": \"Private\",\\n  \"fnlwgt\": 101320,\\n  \"education\": \"Assoc-acdm\",\\n  \"education-num\": 12.0,\\n  \"marital-status\": \"Married-civ-spouse\",\\n  \"occupation\": \"\",\\n  \"relationship\": \"Wift\",\\n  \"race\": \"White\",\\n  \"sex\": \"Female\",\\n  \"capital-gain\": 0,\\n  \"capital-loss\": 1902,\\n  \"hours-per-week\": 40,\\n  \"native-country\": \"United-States\",\\n  \"salary\": \">=50k\"\\n}]', 'task_id': '5ce42145-24b5-4ecd-9e1e-28cd18658cf0', 'batch': 1, 'http_headers': (('Host', '127.0.0.1:5000'), ('User-Agent', 'curl/7.69.1'), ('Accept', '*/*'), ('Content-Type', 'application/json'), ('Content-Length', '370'))}, 'result': {'data': '[\"<50k\"]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '5ce42145-24b5-4ecd-9e1e-28cd18658cf0'}\n",
      "[2021-03-11 17:00:07,422] INFO - {'service_name': 'FastaiTabularModel', 'service_version': '20210311153257_2D1346', 'api': 'predict', 'task': {'data': '[{\\n  \"age\": 49,\\n  \"workclass\": \"Private\",\\n  \"fnlwgt\": 101320,\\n  \"education\": \"Assoc-acdm\",\\n  \"education-num\": 12.0,\\n  \"marital-status\": \"Married-civ-spouse\",\\n  \"occupation\": \"\",\\n  \"relationship\": \"Wift\",\\n  \"race\": \"White\",\\n  \"sex\": \"Female\",\\n  \"capital-gain\": 0,\\n  \"capital-loss\": 1902,\\n  \"hours-per-week\": 40,\\n  \"native-country\": \"United-States\",\\n  \"salary\": \">=50k\"\\n}]', 'task_id': '0a2940aa-0bd4-44cd-b7b1-17796fa6fa78', 'batch': 1, 'http_headers': (('Host', '127.0.0.1:5000'), ('User-Agent', 'curl/7.69.1'), ('Accept', '*/*'), ('Content-Type', 'application/json'), ('Content-Length', '370'))}, 'result': {'data': '[\"<50k\"]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '0a2940aa-0bd4-44cd-b7b1-17796fa6fa78'}\n",
      "^C\n",
      "[2021-03-11 17:01:39 +0000] [1] [INFO] Handling signal: int\n",
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "[2021-03-11 17:01:40 +0000] [11] [INFO] Worker exiting (pid: 11)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "[2021-03-11 17:01:40 +0000] [13] [INFO] Worker exiting (pid: 13)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "[2021-03-11 17:01:40 +0000] [12] [INFO] Worker exiting (pid: 12)\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 5000:5000 fastaitabularmodel:20210311153257_2D1346"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved BentoService\n",
    "\n",
    "bentoml.load is the API for loading a BentoML packaged model in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/bentoml/repository/FastaiTabularModel/20210311153257_2D1346'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-11 17:09:47,350] WARNING - Module `tabular_csv` already loaded, using existing imported module.\n",
      "[2021-03-11 17:09:47,357] WARNING - pip package requirement pandas already exist\n",
      "[2021-03-11 17:09:47,357] WARNING - BentoML by default does not include spacy and torchvision package when using FastaiModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2021-03-11 17:09:47,358] WARNING - pip package requirement torch already exist\n",
      "[2021-03-11 17:09:47,360] WARNING - pip package requirement fastai<2.0.0 already exist\n",
      "['>=50k']\n"
     ]
    }
   ],
   "source": [
    "from bentoml import load\n",
    "\n",
    "svc = load(saved_path)\n",
    "print(svc.predict(df.iloc[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>=50k']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(df.iloc[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch inference job from CLI\n",
    "\n",
    "BentoML cli supports loading and running a packaged model from CLI. With the DataframeInput adapter, the CLI command supports reading input Dataframe data from CLI argument or local csv or json files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/bentoml/gallery/master/fast-ai/salary-range-prediction/test.csv\n",
    "!bentoml run FastaiTabularModel:latest predict \\\n",
    "    --input-file test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Options\n",
    "\n",
    "If you are at a small team with limited engineering or DevOps resources, try out automated deployment with BentoML CLI, currently supporting AWS Lambda, AWS SageMaker, and Azure Functions:\n",
    "- [AWS Lambda Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_lambda.html)\n",
    "- [AWS SageMaker Deployment Guide](https://docs.bentoml.org/en/latest/deployment/aws_sagemaker.html)\n",
    "- [Azure Functions Deployment Guide](https://docs.bentoml.org/en/latest/deployment/azure_functions.html)\n",
    "\n",
    "If the cloud platform you are working with is not on the list above, try out these step-by-step guide on manually deploying BentoML packaged model to cloud platforms:\n",
    "- [AWS ECS Deployment](https://docs.bentoml.org/en/latest/deployment/aws_ecs.html)\n",
    "- [Google Cloud Run Deployment](https://docs.bentoml.org/en/latest/deployment/google_cloud_run.html)\n",
    "- [Azure container instance Deployment](https://docs.bentoml.org/en/latest/deployment/azure_container_instance.html)\n",
    "- [Heroku Deployment](https://docs.bentoml.org/en/latest/deployment/heroku.html)\n",
    "\n",
    "Lastly, if you have a DevOps or ML Engineering team who's operating a Kubernetes or OpenShift cluster, use the following guides as references for implementating your deployment strategy:\n",
    "- [Kubernetes Deployment](https://docs.bentoml.org/en/latest/deployment/kubernetes.html)\n",
    "- [Knative Deployment](https://docs.bentoml.org/en/latest/deployment/knative.html)\n",
    "- [Kubeflow Deployment](https://docs.bentoml.org/en/latest/deployment/kubeflow.html)\n",
    "- [KFServing Deployment](https://docs.bentoml.org/en/latest/deployment/kfserving.html)\n",
    "- [Clipper.ai Deployment Guide](https://docs.bentoml.org/en/latest/deployment/clipper.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
